{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/fcasas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "\n",
    "import keras\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3t7CRUJ9sweH"
   },
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 3. CNN sobre texto\n",
    "\n",
    "Cuando oimos sobre redes neuronales convolucionales (CNN) normalmente pensamos en visión artificial. Las CNN fueron responsables de los principales avances en la clasificación de imágenes y son el núcleo de la mayoría de los sistemas de *Computer Vision* en la actualidad, desde el etiquetado automático de fotos de Facebook hasta los autos que conducen por sí mismos.\n",
    "\n",
    "Más recientemente, también hemos empezado a aplicar CNN a problemas de procesamiento del lenguaje natural (NLP) y hemos obtenido resultados interesantes. Como sabemos, las redes convolucionales tienen importantes ventajas como invarianza a rotaciones y traslaciones así como la conectividad local (características de nivel inferior en una representación de nivel superior), además de lo que las hace fuertemente ventajosas, el **compartir** parámetros.\n",
    "\n",
    "\n",
    "**¿Cómo se aplica esto a NLP?**  \n",
    "En esta experimentación apicaremos una red CNN al dataset  __[Adzuna](https://www.kaggle.com/c/job-salary-prediction)__ que contiene cientos de miles de registros que en su mayoría corresponden a texto no estructurado versus sólo unos pocos estructurados. Los registros pueden estar en varios formatos diferentes debido a los cientos de diferentes fuentes de registros, los cuales corresponden a anuncios de empleadores en busca de trabajadores.  \n",
    "Es decir, cada fila es un anuncio que, en estricto rigor, representa una sentencia típicamente trabajada como vectores de word embeddings como **word2vec** o **GloVe**. Así, para una frase de 10 palabras bajo representaciones de *embeddings* utilizando 100 dimensiones tendríamos una matriz de 10 × 100 como entrada, lo que simularía nuestra \"imagen\".\n",
    "\n",
    "\n",
    "Su tarea es entonces, predecir el salario (valor continuo) de un determinado anuncio en base al texto indicado en éste. Igualmente puede valerse de otros atributos del anuncio como por ejemplo la ubicación, tipo de contrato, etc. \n",
    "\n",
    "\n",
    "A continuación se presenta un código de guía para leer los archivos y pre-procesarlos. Deberá añadir y realizar lo que estime conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = nltk.corpus.stopwords.words('english')\n",
    "df = pd.read_csv(\"all/Train_rev1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TO_WORDNET = {\n",
    "    'JJ':   nltk.corpus.wordnet.ADJ,\n",
    "    'JJR':  nltk.corpus.wordnet.ADJ,\n",
    "    'JJS':  nltk.corpus.wordnet.ADJ,\n",
    "    'RB':   nltk.corpus.wordnet.ADV,\n",
    "    'RBR':  nltk.corpus.wordnet.ADV,\n",
    "    'RBS':  nltk.corpus.wordnet.ADV,\n",
    "    'NN':   nltk.corpus.wordnet.NOUN,\n",
    "    'NNP':  nltk.corpus.wordnet.NOUN,\n",
    "    'NNS':  nltk.corpus.wordnet.NOUN,\n",
    "    'NNPS': nltk.corpus.wordnet.NOUN,\n",
    "    'VB':   nltk.corpus.wordnet.VERB,\n",
    "    'VBG':  nltk.corpus.wordnet.VERB,\n",
    "    'VBD':  nltk.corpus.wordnet.VERB,\n",
    "    'VBN':  nltk.corpus.wordnet.VERB,\n",
    "    'VBP':  nltk.corpus.wordnet.VERB,\n",
    "    'VBZ':  nltk.corpus.wordnet.VERB,\n",
    "}\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    return POS_TO_WORDNET.get(tag,nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "# precompile regexes\n",
    "re1 = re.compile(r'[^\\w]')\n",
    "re2 = re.compile(r'[^\\w]')\n",
    "re3 = re.compile(r'\\b[a-z]\\b')\n",
    "re4 = re.compile(r'\\b[a-z][a-z]\\b')\n",
    "re5 = re.compile(r'\\b[0-9]\\b')\n",
    "re6 = re.compile(r'\\b[0-9][0-9]\\b')\n",
    "re7 = re.compile(r'\\b[0-9][0-9][0-9]\\b')\n",
    "re8 = re.compile(r'[^\\w.]')\n",
    "\n",
    "def preproc_string(s):\n",
    "    s = s.lower()\n",
    "    s = re1.sub(' ',s)\n",
    "    s = re2.sub(' ',s)\n",
    "    s = re3.sub(' ',s)\n",
    "    s = re4.sub(' ',s)\n",
    "    s = re5.sub(' ',s)\n",
    "    s = re6.sub(' ',s)\n",
    "    s = re7.sub(' ',s)\n",
    "    s = re8.sub(' ',s)\n",
    "    text = nltk.word_tokenize(s)\n",
    "    # pos tagging\n",
    "    tags = nltk.pos_tag(text)\n",
    "    # lemmatization\n",
    "    lemms = [lemmatizer.lemmatize(x,penn_to_wn(y)) for x,y in tags]\n",
    "    # remove stopwords\n",
    "    lemms = [x for x in lemms if x not in stoplist]\n",
    "    return lemms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering Systems Analyst Dorking Surrey Salary ****K Our client is located in Dorking, Surrey and are looking for Engineering Systems Analyst our client provides specialist software development Keywords Mathematical Modelling, Risk Analysis, System Modelling, Optimisation, MISER, PIONEEER Engineering Systems Analyst Dorking Surrey Salary ****K\n",
      "\n",
      "['engineering', 'system', 'analyst', 'dorking', 'surrey', 'salary', 'client', 'locate', 'dorking', 'surrey', 'look', 'engineering', 'system', 'analyst', 'client', 'provide', 'specialist', 'software', 'development', 'keywords', 'mathematical', 'modelling', 'risk', 'analysis', 'system', 'model', 'optimisation', 'miser', 'pioneeer', 'engineering', 'system', 'analyst', 'dorking', 'surrey', 'salary']\n"
     ]
    }
   ],
   "source": [
    "print(df['FullDescription'][0])\n",
    "print()\n",
    "print(preproc_string(df['FullDescription'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def len_force(lemms,lim=5):\n",
    "    while(len(lemms)<lim):\n",
    "        lemms.append('')\n",
    "    if len(lemms)>lim:\n",
    "        lemms = lemms[:lim]\n",
    "    return lemms\n",
    "\n",
    "x_words = []\n",
    "for index,x in df.iterrows():\n",
    "    if(index%10000==0):\n",
    "        print(\"%d/%d\"%(index,df.shape[0]))\n",
    "    t1 = len_force(preproc_string(str(x['Title'])),6)\n",
    "    t2 = len_force(preproc_string(str(x['LocationNormalized'])),4)\n",
    "    t3 = len_force(preproc_string(str(x['ContractTime'])),3)\n",
    "    t4 = len_force(preproc_string(str(x['Company'])),7)\n",
    "    t5 = len_force(preproc_string(str(x['FullDescription'])),30)\n",
    "    final = t1 + [''] + t2 + [''] + t3 + [''] + t4 + [''] + t5\n",
    "    x_words.append(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings \n",
    "\n",
    "En lugar de entrenar nuestros vectores embeddings utilizaremos el archivo __[Glove](https://www.kaggle.com/terenceliu4444/glove6b100dtxt#glove.6B.100d.txt)__ el cual cuenta con las representaciones vectoriales (de dimensionalidad 100) ya entrenadas sobre una amplia base de datos. Puede encontrar más detalle en https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SalaryNormalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## embedding dictionary\n",
    "embedd = {}\n",
    "f = open(\"all/glove.6B.100d.txt\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embedd[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label current data\n",
    "vocab_index = {}\n",
    "embedd_matrix = []\n",
    "x = -np.ones((len(x_words),len(x_words[0])),dtype='int')\n",
    "for i in range(len(x_words)):\n",
    "    for j in range(len(x_words[0])):\n",
    "        term = x_words[i][j]\n",
    "        if term not in vocab_index:\n",
    "            if term in embedd:\n",
    "                embedd_matrix.append(embedd[term])\n",
    "                vocab_index[term] = len(vocab_index)\n",
    "        if term in vocab_index:\n",
    "            x[i,j] = vocab_index[term]\n",
    "x[x==-1] = len(vocab_index)\n",
    "embedd_matrix.append(np.zeros(100))\n",
    "embedd_matrix = np.array(embedd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save, just in case\n",
    "np.save(\"all/x.npy\",x)\n",
    "np.save(\"all/e.npy\",embedd_matrix)\n",
    "np.save(\"all/y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"all/x.npy\")\n",
    "embedd_matrix = np.load(\"all/e.npy\")\n",
    "y = np.load(\"all/y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[    0     1     2 ...    24 31594     0]\n",
      " [   25    26    27 ...    46    47    13]\n",
      " [   19    48     2 ...    66    67    68]\n",
      " ...\n",
      " [  544   996 31594 ...  1595   588   633]\n",
      " [ 1001   996 31594 ...    12   996 31594]\n",
      " [ 1057 31594 31594 ...  3348    74   718]]\n",
      "y\n",
      "[25000 30000 30000 ... 22800 22800 42500]\n",
      "embedd_matrix.shape\n",
      "(31595, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"x\")\n",
    "print(x)\n",
    "print(\"y\")\n",
    "print(np.array(y))\n",
    "print(\"embedd_matrix.shape\")\n",
    "print(embedd_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x[:210000]\n",
    "y_tr = y[:210000]\n",
    "x_te = x[210000:]\n",
    "y_te = y[210000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_salary():\n",
    "    max_input_length = 54\n",
    "    inlayer = keras.layers.Input(shape=(max_input_length,))\n",
    "    front = inlayer\n",
    "    #\n",
    "    front = keras.layers.Embedding(input_dim=embedd_matrix.shape[0],output_dim=100,\n",
    "        weights=[embedd_matrix],\n",
    "        input_length=max_input_length,trainable=False)(front)\n",
    "    #\n",
    "    n_filters = [100,160,240,300]\n",
    "    # pool_sizes = [3,2,2,2]\n",
    "    pool_sizes = [3,2,2,2]\n",
    "    for i in range(len(n_filters)):\n",
    "        for _ in range(2):\n",
    "            front = keras.layers.Conv1D(n_filters[i],5,padding='same',\n",
    "                activation='relu',kernel_initializer='he_uniform')(front)\n",
    "        front = keras.layers.MaxPooling1D(pool_size=pool_sizes[i])(front)\n",
    "        front = keras.layers.BatchNormalization()(front)\n",
    "    #\n",
    "    front = keras.layers.Flatten()(front)\n",
    "    front = keras.layers.BatchNormalization()(front)\n",
    "    for k in range(3):\n",
    "        front = keras.layers.Dense(800,activation='relu',\n",
    "                                  kernel_initializer='he_uniform')(front)\n",
    "        front = keras.layers.BatchNormalization()(front)\n",
    "    front = keras.layers.Dense(1,activation='tanh',\n",
    "                              kernel_initializer='glorot_uniform')(front)\n",
    "    mean = np.mean(y_tr)\n",
    "    std = np.std(y_tr)\n",
    "    \n",
    "    front = keras.layers.Lambda(lambda x: mean+5*x*std)(front)\n",
    "    #\n",
    "    model = keras.models.Model(inputs=inlayer,outputs=front)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 54)                0         \n",
      "_________________________________________________________________\n",
      "embedding_33 (Embedding)     (None, 54, 100)           3159500   \n",
      "_________________________________________________________________\n",
      "conv1d_246 (Conv1D)          (None, 54, 100)           50100     \n",
      "_________________________________________________________________\n",
      "conv1d_247 (Conv1D)          (None, 54, 100)           50100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 18, 100)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 18, 100)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_248 (Conv1D)          (None, 18, 160)           80160     \n",
      "_________________________________________________________________\n",
      "conv1d_249 (Conv1D)          (None, 18, 160)           128160    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 9, 160)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 9, 160)            640       \n",
      "_________________________________________________________________\n",
      "conv1d_250 (Conv1D)          (None, 9, 240)            192240    \n",
      "_________________________________________________________________\n",
      "conv1d_251 (Conv1D)          (None, 9, 240)            288240    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4, 240)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 4, 240)            960       \n",
      "_________________________________________________________________\n",
      "conv1d_252 (Conv1D)          (None, 4, 300)            360300    \n",
      "_________________________________________________________________\n",
      "conv1d_253 (Conv1D)          (None, 4, 300)            450300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2, 300)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 2, 300)            1200      \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 600)               2400      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 800)               480800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 801       \n",
      "_________________________________________________________________\n",
      "lambda_28 (Lambda)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 6,537,501\n",
      "Trainable params: 3,370,401\n",
      "Non-trainable params: 3,167,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_salary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210000 samples, validate on 34768 samples\n",
      "Epoch 1/25\n",
      "210000/210000 [==============================] - 149s 710us/step - loss: 31548.2582 - val_loss: 19094.1255\n",
      "Epoch 2/25\n",
      "210000/210000 [==============================] - 139s 663us/step - loss: 16583.2443 - val_loss: 17407.8603\n",
      "Epoch 3/25\n",
      "210000/210000 [==============================] - 124s 589us/step - loss: 14560.4702 - val_loss: 13283.5485\n",
      "Epoch 4/25\n",
      "210000/210000 [==============================] - 123s 584us/step - loss: 12832.3514 - val_loss: 12447.1543\n",
      "Epoch 5/25\n",
      "210000/210000 [==============================] - 122s 581us/step - loss: 11896.9445 - val_loss: 13800.3196\n",
      "Epoch 6/25\n",
      "210000/210000 [==============================] - 125s 597us/step - loss: 11155.0692 - val_loss: 12502.9053\n",
      "Epoch 7/25\n",
      " 15750/210000 [=>............................] - ETA: 1:51 - loss: 11179.2423"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-82eaefc2cb5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m history = model.fit(x_tr,y_tr,validation_data=(x_te,y_te),\n\u001b[0;32m---> 10\u001b[0;31m           epochs=EPOCHS,batch_size=350)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Music/p36env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Music/p36env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Music/p36env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Music/p36env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Music/p36env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "model = model_salary()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=1e-2,decay=1.0/EPOCHS)\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer=optimizer)\n",
    "\n",
    "history = model.fit(x_tr,y_tr,validation_data=(x_te,y_te),\n",
    "          epochs=EPOCHS,batch_size=350)\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('history.json', 'w') as f:\n",
    "    json.dump(history.history,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de predicciones\n",
    "Para las predicciones evalúe la métrica *Mean Absolute Error* (MAE)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE on train: \",mean_absolute_error(y_train, model.predict(Xtrain)))\n",
    "print(\"MAE on validation: \",mean_absolute_error(y_val, model.predict(Xval)))\n",
    "```\n",
    "\n",
    "> **Intente resolver el problema experimentando con las ayudas que se entregan en el código y lo aprendido hasta ahora en el curso. Se espera que llegue a un MAE menor a 7000 en el conjunto de pruebas. No olvide documentar todo lo experimentando en este Informe Jupyter así como el argumento de sus decisiones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado_T2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
