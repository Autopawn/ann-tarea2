{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3t7CRUJ9sweH"
   },
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 3. CNN sobre texto\n",
    "\n",
    "Cuando oimos sobre redes neuronales convolucionales (CNN) normalmente pensamos en visión artificial. Las CNN fueron responsables de los principales avances en la clasificación de imágenes y son el núcleo de la mayoría de los sistemas de *Computer Vision* en la actualidad, desde el etiquetado automático de fotos de Facebook hasta los autos que conducen por sí mismos.\n",
    "\n",
    "Más recientemente, también hemos empezado a aplicar CNN a problemas de procesamiento del lenguaje natural (NLP) y hemos obtenido resultados interesantes. Como sabemos, las redes convolucionales tienen importantes ventajas como invarianza a rotaciones y traslaciones así como la conectividad local (características de nivel inferior en una representación de nivel superior), además de lo que las hace fuertemente ventajosas, el **compartir** parámetros.\n",
    "\n",
    "\n",
    "**¿Cómo se aplica esto a NLP?**  \n",
    "En esta experimentación apicaremos una red CNN al dataset  __[Adzuna](https://www.kaggle.com/c/job-salary-prediction)__ que contiene cientos de miles de registros que en su mayoría corresponden a texto no estructurado versus sólo unos pocos estructurados. Los registros pueden estar en varios formatos diferentes debido a los cientos de diferentes fuentes de registros, los cuales corresponden a anuncios de empleadores en busca de trabajadores.  \n",
    "Es decir, cada fila es un anuncio que, en estricto rigor, representa una sentencia típicamente trabajada como vectores de word embeddings como **word2vec** o **GloVe**. Así, para una frase de 10 palabras bajo representaciones de *embeddings* utilizando 100 dimensiones tendríamos una matriz de 10 × 100 como entrada, lo que simularía nuestra \"imagen\".\n",
    "\n",
    "\n",
    "Su tarea es entonces, predecir el salario (valor continuo) de un determinado anuncio en base al texto indicado en éste. Igualmente puede valerse de otros atributos del anuncio como por ejemplo la ubicación, tipo de contrato, etc. \n",
    "\n",
    "\n",
    "A continuación se presenta un código de guía para leer los archivos y pre-procesarlos. Deberá añadir y realizar lo que estime conveniente.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "stoplist = stopwords.words('english')\n",
    "#lemmatizer (WordNetLemmatizer())\n",
    "#stemming?\n",
    "\n",
    "df=pd.read_csv(\"Train_rev1.csv\")\n",
    "df.head()\n",
    "\n",
    "def pre_procesar(df):\n",
    "    #preprocesar texto de los anuncios\n",
    "    #Eliminación de stopwords, stemming/lemmatization, puntuación, etc\n",
    "    for s in textos:\n",
    "        s= s.lower()\n",
    "        s= re.sub(r'[^\\w]', ' ',s)\n",
    "        s= re.sub(r'\\b[a-z]\\b', ' ',  s)\n",
    "        s= re.sub(r'\\b[a-z][a-z]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9][0-9]\\b', ' ',  s)\n",
    "        s=re.sub(r'\\b[0-9][0-9][0-9]\\b', ' ',  s)\n",
    "        s= re.sub(r'[^\\w.]', ' ', s)\n",
    "        s= list(s.split())\n",
    "        #s= eliminación de stopwords\n",
    "        #s= stemming o lemmatization\n",
    "        #guardar texto procesado\n",
    "        \n",
    "    return df_procesado \n",
    "  ```\n",
    " \n",
    "```python\n",
    "y_dataframe=df['SalaryNormalized'].values\n",
    "x_dataframe=df[['FullDescription',...]]\n",
    "\n",
    "k=len(df_procesado)\n",
    "x_train=df_procesado[0:int(k*0.70)] #70% training\n",
    "x_val=df_procesado[int(k*0.70):int(k*0.85)] #15% validation\n",
    "x_test=df_procesado[int(k*0.85):] #15% test\n",
    "```\n",
    "\n",
    "### Embeddings \n",
    "\n",
    "En lugar de entrenar nuestros vectores embeddings utilizaremos el archivo __[Glove](https://www.kaggle.com/terenceliu4444/glove6b100dtxt#glove.6B.100d.txt)__ el cual cuenta con las representaciones vectoriales (de dimensionalidad 100) ya entrenadas sobre una amplia base de datos. Puede encontrar más detalle en https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "```python\n",
    "##armar diccionario word, index para posterior construccion de matriz de embeddings de glove\n",
    "word_index=dict()\n",
    "j=0\n",
    "for frase in x_train:\n",
    "    seq=frase.split()\n",
    "    for term in seq:\n",
    "        if term not in word_index.keys():\n",
    "            word_index[term]=j\n",
    "            j+=1\n",
    "            \n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Se encontraron %s terminos con sus vectores de embedding.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_vector=100\n",
    "embedding_matrix = np.zeros((len(word_index.keys()), embedding_vector))   #puede probar otra inicialización\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words sin match en Glove, serán vectores de ceros.\n",
    "        embedding_matrix[i] = embedding_vector    \n",
    "        \n",
    "```\n",
    "### Modelo\n",
    "\n",
    "```python\n",
    "\"\"\"Definir input para el modelo: \"\"\"\n",
    "from keras.preprocessing import sequence\n",
    "x_new_train = [[word_index[word] for word in text.split()] for text in x_train]\n",
    "x_new_val = [[word_index[word] for word in text.split() if word in word_index] for text in x_val]\n",
    "\n",
    "max_input_lenght = 150 #modificar este valor en base a su experimentación\n",
    "Xtrain = sequence.pad_sequences(x_new_train,maxlen=max_input_lenght,padding='post',value=0)\n",
    "Xval = sequence.pad_sequences(x_new_val,maxlen=max_input_lenght,padding='post',value=0)\n",
    "\n",
    "\"\"\"Define model trough Model API in Keras\"\"\"\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "embedding_vector=100\n",
    "embedding_layer = Embedding(input_dim=len(word_index.keys()),output_dim=embedding_vector,weights=[embedding_matrix],\n",
    "                     input_length=max_input_lenght,trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(max_input_lenght,))\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "cov1= Conv1D(128, 5, activation='relu',padding='same')(embedded_sequences)\n",
    "pool = MaxPooling1D(pool_size=)(cov1)\n",
    "...\n",
    "flat = Flatten()(layerK)\n",
    "preds = Dense(1, activation='linear')(flat)\n",
    "model = Model(sequence_input, preds)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(Xtrain, y_train, validation_data=(Xval, y_val),epochs=25, batch_size=256)\n",
    "```\n",
    "### Evaluación de predicciones\n",
    "Para las predicciones evalúe la métrica *Mean Absolute Error* (MAE)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"MAE on train: \",mean_absolute_error(y_train, model.predict(Xtrain)))\n",
    "print(\"MAE on validation: \",mean_absolute_error(y_val, model.predict(Xval)))\n",
    "```\n",
    "\n",
    "> **Intente resolver el problema experimentando con las ayudas que se entregan en el código y lo aprendido hasta ahora en el curso. Se espera que llegue a un MAE menor a 7000 en el conjunto de pruebas. No olvide documentar todo lo experimentando en este Informe Jupyter así como el argumento de sus decisiones.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado_T2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
